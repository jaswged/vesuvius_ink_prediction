{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Vesuvius - Data_trn_val_tst\n",
    "Manually translated from [here](https://www.kaggle.com/code/synset/vesuvius-data-trn-val-tst)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install qunet\n",
    "#!pip -q install torchinfo        # model structure\n",
    "\n",
    "import os, gc, sys, time, datetime, math, random, copy, psutil, glob\n",
    "import numpy as np,  matplotlib.pyplot as plt, pandas as pd\n",
    "from pathlib import Path\n",
    "import PIL.Image as Image\n",
    "from   tqdm.auto import tqdm\n",
    "import torch, torch.nn as nn\n",
    "from torchinfo import summary\n",
    "\n",
    "from qunet import Info, Config, Callback, Data,  MLP, Transformer, plot_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CFG = Config(\n",
    "    folder_trn  = '/kaggle/input/vesuvius-challenge-ink-detection/train/',\n",
    "    folder_tst  = '/kaggle/input/vesuvius-challenge-ink-detection/test/',\n",
    "\n",
    "    layer_min = 0,\n",
    "    layer_max = 5,   # !!!!\n",
    "\n",
    "    patch_h  = 512,  # the height and width of the patches into which the image is split\n",
    "    patch_w  = 512,\n",
    "\n",
    "    train    = True,  # the model is trained or loaded from a dataset trained before submission\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    ")\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "info = Info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Class VesuviusData\n",
    "Large Images (H, W) from (7606, 5249) to (14830, 9506). For 65 slices occupy 4*(65*14830*9506) = 34 GB of memory.\n",
    "For model to work must split image into patches of small sizes (h, w).\n",
    "\n",
    "For augmentation, these patches should be cut from random places and made in different sizes.\n",
    "When testing the patches should completely cover the image with regular tiling.\n",
    "If an integer number of patches does not fit, edge bands with overlapping patches are needed.\n",
    "Apparently a better option with overlap and subsequent averaging or replacement\n",
    "\n",
    "We must not forget to try TTA (several oaz go through different sizes, including randomly and average the cumulative mask.\n",
    "Erosion removal\n",
    "\n",
    "## Validation problems\n",
    "\n",
    "With random splitting, validation may overlap with training patches. Let them overlap. Trust your CV.\n",
    "\n",
    "## Uploading a new file.\n",
    "For loading use the callback class.\n",
    "In all modes the requested number of n_patches must be chosen so that they fit into memory. (taking into account their sizes)\n",
    "In training and validation mode, after loading all the masks, all n_patches are sent to the tensors of the dataset. (i.e. Reload woks in one pass.\n",
    "\n",
    "In test mode the maximum number of patches is determined by the image size and the patch size. Therefore, the requested number of patches n_patches may be less (to fit into memory). Then reload will select the patches formed by tiling several times.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DataManagerCallback(Callback):\n",
    "    def __init__(self, data, train, n_patches, rand=True,\n",
    "                 patch_h = 64, patch_w = 64, patch_dh = 0, patch_dw = 0,\n",
    "                 shuffle=False, batch_size=64,  whole_batch=False,\n",
    "                 layer_min=0, layer_max=65):\n",
    "\n",
    "        self.train       = train     # Training (validation) or testing\n",
    "        self.n_patches   = n_patches # patch count in self.data\n",
    "        self.patch_h0    = patch_h   # patch height (average value)\n",
    "        self.patch_w0    = patch_w   # patch width\n",
    "        self.patch_dh    = patch_dh  # deviations from patch_h0 (random deviations from average sizes)\n",
    "        self.patch_dw    = patch_dw  # deviations from patch_w0\n",
    "        self.rand        = rand      # random patch positions\n",
    "\n",
    "        self.layer_min   = layer_min\n",
    "        self.layer_max   = layer_max\n",
    "        self.n_layers    = layer_max-layer_min  # number of fragment layers (65)\n",
    "        assert self.n_layers <= 65, \"Wrong number of layers\"\n",
    "\n",
    "        self.data        = data      # instance of Data\n",
    "        self.period_reload = 1       # period in epochs for which we load a new fragment\n",
    "\n",
    "        self.fast        = False     # Fast patching without mas control, otherwise only under the fragment\n",
    "        self.patches_pos = None      # (N,2) tensor of N pathes pos (y,x)\n",
    "        self.patch_id    = 0         # current starting patch number in patches_pos\n",
    "        self.folder_id   = 0         # current id of folder from list self.folders:\n",
    "        self.next_new_file = False   #The next call to reload will load the new fragment\n",
    "\n",
    "        # In train/val mode we use CFG.folder_trn, when testing (submission) CFG.folder_tst\n",
    "        self.folders = sorted(list(Path(CFG.folder_trn if train else CFG.folder_tst).glob('*')))\n",
    "        info(f\"VesuviusData: tarin={train}, {len(self.folders)} subfoders (scroll fragments)\")\n",
    "\n",
    "        # Wehn creating an instance of VesuviusData, the data is not loaded.\n",
    "        # To do this, call the reset method. The same method is called by the trainer before the start of fit\n",
    "        # Inside fit, the reload method is called periodically `period_reload`\n",
    "\n",
    "    #---------------------------------------------------------------------------\n",
    "\n",
    "    def load_masks(self, folder, verbose=1):\n",
    "        \"\"\"\n",
    "        Upload fragment and ink mask files from folder\n",
    "        \"\"\"\n",
    "        self.files = sorted( (folder / Path(\"surface_volume/\")).glob('*.tif') )\n",
    "        assert len(self.files) == 65, f\"Wrong numer of files: {len(self.files)}\"\n",
    "\n",
    "        fname_mask  = folder / Path(\"mask.png\")\n",
    "        self.mask = torch.from_numpy(np.array(Image.open(fname_mask).convert('1')))\n",
    "        if verbose >= 1: info(f\"loaded mask: {self.mask.shape} from {folder}\")\n",
    "        if self.train: # In test mode there are no ink labels\n",
    "            fname_ink = folder / Path(\"inklabels.png\")\n",
    "            self.ink  = torch.from_numpy(np.array(Image.open(fname_ink) .convert('1')))\n",
    "            if verbose >= 1: info(f\"loaded ink : {self.ink.shape}\")\n",
    "\n",
    "        # Random deviations from typical patch size\n",
    "        self.patch_h = self.patch_h0 + torch.randint(-self.patch_dh, self.patch_dh+1,(1,)).item()\n",
    "        self.patch_w = self.patch_w0 + torch.randint(-self.patch_dw, self.patch_dw+1,(1,)).item()\n",
    "\n",
    "        # After this method, get_patches_pos, should be called, which generates a list of patch coordinates\n",
    "        # and allocates memory for their subset. The reload method will fill this memory until the list of patches ends.\n",
    "        # After that, the next fragment wil be loaded and the story repeats\n",
    "\n",
    "    #---------------------------------------------------------------------------\n",
    "\n",
    "    def get_patches_pos(self):\n",
    "        \"\"\"\n",
    "        Creates (N,2) tensor with the positions of the top-left corners of the patches.\n",
    "        Сreate data tensors\n",
    "        It works in two modes: random patches and dense tiling from patches for training and validation.\n",
    "         We use randomly cut patches from a fragment (at the edges with overlap)\n",
    "        \"\"\"\n",
    "        (H,W), h,w, n = self.mask.shape, self.patch_h, self.patch_w, self.n_patches\n",
    "\n",
    "        if self.rand:  # random positions\n",
    "            if self.fast:\n",
    "                posY = torch.randint(0, H-h, (self.n_patches,1))  # patch position top-lef corner\n",
    "                posX = torch.randint(0, W-w, (self.n_patches,1))  #\n",
    "                self.patches_pos = torch.hstack([posY,posX])      # список координта патчей\n",
    "            else:\n",
    "                self.patches_pos = torch.empty((self.n_patches,2), dtype=torch.long)\n",
    "                patch_id = 0\n",
    "                while patch_id < self.n_patches:\n",
    "                    y = torch.randint(0, H-h, (1,)).item()     # patch position top-lef corner\n",
    "                    x = torch.randint(0, W-w, (1,)).item()\n",
    "                    if self.mask[y:y+h, x:x+w].sum():          # Patch coordinate list\n",
    "                        self.patches_pos[patch_id, 0] = y\n",
    "                        self.patches_pos[patch_id, 1] = x\n",
    "                        patch_id += 1\n",
    "\n",
    "\n",
    "        else:          # tiling (maybe with overlap on the right and bottom of image)\n",
    "            posY = torch.IntTensor(list(range(0,H-h,h)) + ([H-h] if H % h else []) )\n",
    "            posX = torch.IntTensor(list(range(0,W-w,w)) + ([W-w] if W % w else []) )\n",
    "            self.patches_pos = torch.cartesian_prod(posY,posX)\n",
    "            self.n_patches = min(self.n_patches, len(self.patches_pos)) # cannot exceed the number of patches `patches_pos`\n",
    "\n",
    "        self.patch_id = 0 # Number of the first example to form examples for tensors\n",
    "\n",
    "    #---------------------------------------------------------------------------\n",
    "\n",
    "    def get_patches(self, verbose):\n",
    "        \"\"\"\n",
    "        Get tensors patches.\n",
    "        Return False if all positions from patches_pos are selected\n",
    "        \"\"\"\n",
    "        # We take a subset of n patches, starting the patch with patch patch_id number\n",
    "        patches_pos = self.patches_pos[self.patch_id: self.patch_id +  self.n_patches].numpy()\n",
    "\n",
    "        # We callocate memory for dataset tensors. The number of examles is less than or equal to the number of patches in `patches_pos`\n",
    "        n, h,w = len(patches_pos), self.patch_h, self.patch_w\n",
    "        self.data.data = [torch.empty( n,self.n_layers, h,w ),            # patches by layers\n",
    "                          torch.empty((n,1,h,w), dtype=self.mask.dtype ), # fragment mask\n",
    "                          torch.empty((n,1,h,w), dtype=self.mask.dtype ), # ink mask (target)\n",
    "                          torch.empty((n,2),     dtype=torch.int32 ) ]    # patch positions\n",
    "\n",
    "        # Filing the tensors of the dataset\n",
    "        # todo: eliminate cycles (???)\n",
    "        self.data.data[1][:,0,:,:] = torch.vstack([self.mask[y:y+h, x:x+w].view(1,h,w) for (y,x) in patches_pos])\n",
    "        if self.train:\n",
    "            self.data.data[2][:,0,:,:] = torch.vstack([self.ink [y:y+h, x:x+w].view(1,h,w) for (y,x) in patches_pos])\n",
    "        else:\n",
    "            self.data.data[2] = self.data.data[1]\n",
    "        self.data.data[3] = torch.vstack([torch.IntTensor([y,x]).view(1,2) for (y,x) in patches_pos])\n",
    "\n",
    "        # Load images of slices one by one and split each of them into patches with coordinates from patches_pos\n",
    "        for d in range(self.layer_min,  self.layer_max):\n",
    "            image = torch.tensor( np.array(Image.open(self.files[d] ), dtype=np.float32) / 65535.0 )\n",
    "            assert self.mask.shape == image.shape\n",
    "\n",
    "            patches = torch.vstack([image[y:y+h, x:x+w].view(1,h,w) for (y,x) in patches_pos])\n",
    "            self.data.data[0][:, d-self.layer_min, :, :] = patches\n",
    "\n",
    "            if verbose >= 2: print(f\"\\rdepth:{d:2d}, {self.data.data[0].shape};  {self.data.data[0].is_contiguous()}\", end =\"    \")\n",
    "\n",
    "        self.patch_id += self.n_patches\n",
    "        if verbose >= 2: print(f\" layers loaded, patch_id={self.patch_id}.\")\n",
    "\n",
    "        return self.patch_id >= len(self.patches_pos)  # True, if the self.patches_pos list is over\n",
    "\n",
    "    #---------------------------------------------------------------------------\n",
    "\n",
    "    def reload(self, train=True, epoch=0, hist=Config(), best=Config(), verbose=1):\n",
    "        \"\"\"\n",
    "        Called in the trainer.fit() function, every period_reload epochs.\n",
    "        \"\"\"\n",
    "        # Initial loading of masks and generating a list of patch coordinates\n",
    "        # We do this only at the beginning (and not when we select the list of coordinates\n",
    "        if self.next_new_file:\n",
    "            self.next_new_file = False\n",
    "            self.folder_id = (self.folder_id + 1) % len(self.folders)   # Fragments are numbered in a circle\n",
    "            self.patch_id  = 0\n",
    "\n",
    "            self.load_masks(self.folders[self.folder_id], verbose)      # upload fragment and ink masks\n",
    "            self.get_patches_pos()                                      # create positions of patches\n",
    "\n",
    "        # Fill the tensors of the dataset with patches with masks and fragment layers un der the patches.\n",
    "        # get_patches will return True, when the entire list of coordinates has been selected\n",
    "        # if this happens, next time we load the next fragment\n",
    "        # Immediately impossible, because it will be necessary to first process the loaded files in the batch iterator\n",
    "        if self.get_patches(verbose):                                   # all patches are selected\n",
    "            self.next_new_file = True                                   # load a new file on the next call\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    #---------------------------------------------------------------------------\n",
    "\n",
    "    def on_fit_start(self, trainer, model):\n",
    "        \"\"\"\n",
    "        Called before the trainer.fit() function starts running\n",
    "        Before starting fit, load the first fragment, split it into patches,\n",
    "        and form the dataset tensors from the initial subset of pataches\n",
    "        \"\"\"\n",
    "        self.folder_id = -1\n",
    "        self.next_new_file = True\n",
    "\n",
    "        #---------------------------------------------------------------------------\n",
    "\n",
    "    def on_train_epoch_start(self, trainer, model):\n",
    "        \"\"\"\n",
    "        Called when epoch in fit ends.\n",
    "        \"\"\"\n",
    "        if trainer is None or  (trainer.epoch == 1 or trainer.epoch % self.period_reload == 0):\n",
    "            self.reload(verbose = 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating validation and training datasets\n",
    "We will make validation static by uploading 3 files once, splitting them into patches and collecting all the patches into one dataset.\n",
    "To add one dataset to another, the data class has an add method.\n",
    "The breakdown result can be seen in the visualization section"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Validation:\n",
    "info.reset()(\"beg\")\n",
    "data_val = Data(batch_size=50)\n",
    "data_tmp = Data()\n",
    "callback = DataManagerCallback (data=data_tmp, train=True, n_patches=200, rand=True,\n",
    "                                patch_h=CFG.patch_h, patch_w=CFG.patch_w, layer_min=CFG.layer_min, layer_max=CFG.layer_max)\n",
    "callback.on_fit_start(None,0)\n",
    "for i in range(3):            # 200 patches 3 times ( From each fragment)\n",
    "    callback.on_train_epoch_start(None,0)\n",
    "    data_val.add(callback.data)\n",
    "info(f\"data_val samples = {data_val.count()}  batches = {len(data_val)}\")\n",
    "\n",
    "# Training (validation callback is not needed already):\n",
    "data_trn = Data(batch_size=100, shuffle=True)\n",
    "callback = DataManagerCallback (data=data_trn, train=True, n_patches=1000, rand=True,\n",
    "                                patch_h=CFG.patch_h, patch_w=CFG.patch_w, patch_dh=16, patch_dw=16,\n",
    "                                layer_min=CFG.layer_min, layer_max=CFG.layer_max)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# We imitate a coach"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, data_trn, data_val = data_val, callbacks=[]):\n",
    "        self.data      = Config(trn=data_trn, val=data_val)\n",
    "        self.callbacks = callbacks\n",
    "        self.epoch     = 0\n",
    "\n",
    "    def fit(self, epochs, period_reload=1):\n",
    "        \"\"\" Imitate the fit method \"\"\"\n",
    "        for callback in self.callbacks: callback.on_fit_start(self, 0)\n",
    "        for epoch in range(1, epochs+1):\n",
    "            self.epoch = epoch\n",
    "\n",
    "            info(\"training start\")\n",
    "            for callback in self.callbacks: callback.on_train_epoch_start(self, 0)\n",
    "            for batch_id, batch in enumerate(self.data.trn):\n",
    "                info.info(f\"\\r{batch_id+1}: {batch[0].shape}\", pref=\"\\r\", end=\"   \")\n",
    "            print(f\" {len(data_trn)} batches\")\n",
    "\n",
    "            info(\"validation start\")\n",
    "            for batch_id, batch in enumerate(self.data.trn):\n",
    "                info.info(f\"\\r{batch_id+1}: {batch[0].shape}\", pref=\"\\r\", end=\"   \")\n",
    "            print(f\" {len(data_trn)} batches\")\n",
    "\n",
    "\n",
    "trainer = Trainer(data_trn, callbacks=[callback])\n",
    "trainer.fit(epochs=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Submission"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def submission(patch_h, patch_w):\n",
    "    result = {}\n",
    "    ink_pred = None\n",
    "\n",
    "    data_tst = Data(batch_size=100)\n",
    "    callback = DataManagerCallback(data=data_tst, train=False, n_patches=1000, rand=False,\n",
    "                                   patch_h=CFG.patch_h, patch_w=CFG.patch_w, patch_dh=0, patch_dw=0,\n",
    "                                   layer_min=CFG.layer_min, layer_max=CFG.layer_max)\n",
    "    callback.on_fit_start(None, 0)\n",
    "    while True:                # on patches\n",
    "        callback.on_train_epoch_start(None, 0)\n",
    "\n",
    "        if ink_pred is None:\n",
    "            ink_pred = np.ones_like(callback.mask)\n",
    "            folder = callback.folders[callback.folder_id].parts[-1]\n",
    "            print(f\"\\n*** Create new mask {ink_pred.shape}  folder:{folder}\\n\")\n",
    "\n",
    "        for batch_id, batch in enumerate(data_tst):\n",
    "            patches, mask, ink, pos = batch\n",
    "            for (y,x) in pos:\n",
    "                ink_pred[y:y+patch_h, x:x+patch_w] = 0  # Check that all pixels are covered with patches\n",
    "\n",
    "        if callback.next_new_file:\n",
    "            # Before uploading a new file, save the mask to submissions\n",
    "            ink_pred[0,1]=ink_pred[1,0]=1 # для csv\n",
    "            result[folder] = \"\"           # !\n",
    "            print(f\"\\n*** Save submission to '{folder}'; ink_pred.shape:{ink_pred.shape}, sum:{ink_pred.sum()} == 2\\n\")\n",
    "            ink_pred = None\n",
    "\n",
    "            if callback.folder_id + 1 >=  len(callback.folders):\n",
    "                break\n",
    "\n",
    "    info(f\"result: {result}\")\n",
    "    #pd.DataFrame(result).to_csv(\"submission.csv\")  # todo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "info(\"beg\")\n",
    "#del data_trn, data_val\n",
    "submission(patch_h=CFG.patch_h, patch_w=CFG.patch_w)\n",
    "info(f\"the End\");"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_masks(folder=CFG.folder_trn,  subfolder=\"1/\", w=10, h=6):\n",
    "    path = Path(folder) / Path(subfolder)\n",
    "\n",
    "    sample = Image.open(path / Path(\"ir.png\"))\n",
    "    label = torch.from_numpy(np.array(Image.open(path / Path(\"inklabels.png\")) )).gt(0).float().to(CFG.device)\n",
    "    mask = np.array(Image.open(path / Path(\"mask.png\")).convert('1'))\n",
    "\n",
    "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(w, h), facecolor ='w')\n",
    "    ax0.set_title(subfolder+\"ir.png\");         ax0.imshow(sample,      cmap='gray')\n",
    "    ax1.set_title(subfolder+\"inklabels.png\");  ax1.imshow(label.cpu(), cmap='gray')\n",
    "    ax1.set_title(subfolder+\"mask.png\");       ax1.imshow(mask,        cmap='gray', alpha=0.5)\n",
    "    plt.show()\n",
    "    print(f\"label: {label.shape},  mask: {mask.shape}\")\n",
    "\n",
    "info(\"beg\"); plot_masks(subfolder=\"1/\"); info(\"end\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_data(folder=CFG.folder_trn,  subfolder=\"1/\", start=0, num=4,  w=12, h=6):\n",
    "    \"\"\" Load the 3d x-ray scan, one slice at a time \"\"\"\n",
    "    path  = Path(folder) / Path(subfolder) / Path(\"surface_volume/\")\n",
    "    files = sorted( path.glob('*.tif') )\n",
    "    print(f\"total files: {len(files)}\")\n",
    "    images = [np.array(Image.open(fname), dtype=np.float32) / 65535.0 \\\n",
    "              for fname in tqdm(files[start:start+num])  ]\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(w, h))\n",
    "    for image, ax in zip(images, axes):\n",
    "        ax.imshow(np.array(Image.fromarray(image).resize((image.shape[1]//20, image.shape[0]//20)), dtype=np.float32), cmap='gray')\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "info(\"beg\"); plot_data(subfolder=\"1/\"); info(\"end\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_patches(data, idx=0, n_images=5, w=12, h=4, start=0):\n",
    "    data.reset()\n",
    "    for patch,  mask, ink, pos in data:\n",
    "        print(patch.shape, mask.shape, ink.shape)\n",
    "        break\n",
    "\n",
    "    images =  [mask[idx][0].float().numpy(), ink[idx][0].float().numpy()]\n",
    "    images += [patch[idx, start+i].numpy() for i in range(n_images-3) ]\n",
    "    images += [ patch[idx].mean(0).numpy()]\n",
    "    fig, axes = plt.subplots(1, n_images, figsize=(w, h))\n",
    "    for i, (image, ax) in enumerate(zip(images, axes)):\n",
    "        ax.imshow(image, cmap='gray', vmin=0, vmax=1)\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        if i==0:\n",
    "            ax.set_title(f\"y:{pos[idx][0]}, x:{pos[idx][1]}\", fontsize=8)\n",
    "        #elif i > 1:\n",
    "        #    ax.set_title(f\"{patch[idx,start+i-2].min()} {patch[idx,start+i-2].max()} {patch[idx,start+i-2].std():.2f}\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for idx in range(20):\n",
    "    plot_patches(data_val, idx=idx)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
